import pandas as pd 
import numpy as np


data=pd.read_csv('C:/Users/bipin/predicting house price/Bengaluru_House_Data.csv')


data.drop(columns=['society'],inplace=True)


data.dropna(inplace=True)


data.location.value_counts()


data['location']=data['location'].apply(lambda x:x.strip())


data.location.value_counts()


location_stats=data.groupby('location')['location'].agg('count').sort_values(ascending=False)





location_less_than_10_entries=location_stats[location_stats<=10]


location_less_than_10_entries


data['location']=data['location'].apply(lambda x:'other' if x in location_less_than_10_entries else x)


data['location'].value_counts()


data


data['size'].unique()


data['bedrooms']=data['size'].apply(lambda x:int (x.split(' ')[0])) 


data


data.total_sqft.unique()


def clean(sqft):
    tokens=sqft.split('-')
    if len(tokens)==2:
        return (float(tokens[0])+float(tokens[1]))/2
    else:
        try:
            return float(sqft)
        except:
            return None


data['total_sqft']=data['total_sqft'].apply(clean)


data.total_sqft.unique()


data.dropna(inplace=True)


data.describe()


data['sqft_per_bed']=data['total_sqft']/data['bedrooms']


data.sqft_per_bed.describe()


data2=data[data['sqft_per_bed']>=300]


data2


data2['price_per_sqft']=round(data2['price']*100000/data2['total_sqft'])


data2.price_per_sqft.describe()


data3=data2[data2['price_per_sqft']>=200]


data3.drop(columns=['size','sqft_per_bed','price_per_sqft'],axis=1,inplace=True)


data3


from sklearn.preprocessing import OneHotEncoder,StandardScaler


from sklearn.model_selection import train_test_split


from sklearn.linear_model import LinearRegression


from sklearn.pipeline import make_pipeline


from sklearn.compose import make_column_transformer


from sklearn.preprocessing import OneHotEncoder

col_trans = make_column_transformer(
    (OneHotEncoder(sparse_output=False, handle_unknown='ignore'), ['location']),
    remainder='passthrough'
)



lr=LinearRegression()


scaler=StandardScaler()


model=make_pipeline(col_trans,scaler,lr)


data_input=data3.drop(columns=['price'])
data_output=data3['price']


x_train,x_test,y_train,y_test=train_test_split(data_input,data_output,test_size=0.2)


model.fit(x_train,y_train)


print(type(x_test))


print(x_test.columns)


x_test = pd.DataFrame(x_test, columns=data_input.columns)


assert isinstance(x_test, pd.DataFrame), "x_test must be a DataFrame"
assert all(col in x_test.columns for col in ['location']), "Missing 'location' column"


model.score(x_test, y_test)


input_df = pd.DataFrame([['Electronic City Phase II',2000.0, 3.0, 2.0, 3]],
                        columns=['location', 'total_sqft', 'bath', 'balcony', 'bedrooms'])


model.predict(input_df)


import pickle as pk



pk.dump(model,open('House_prediction_model1.pkl','wb'))


data3.to_csv('Cleaned_data1.csv')



